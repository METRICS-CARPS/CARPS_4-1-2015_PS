---
title: "CARPS Reproducibility Report"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r}
articleID <- "4-1-2015_PS" # insert the article ID code here e.g., "10-3-2015_PS"
reportType <- 'final'
pilotNames <- "Sean Zion, Mufan Luo" # insert the pilot's name here e.g., "Tom Hardwicke". If there are multiple pilots enter both names in a character string e.g., "Tom Hardwicke, Bob Dylan"
copilotNames <- "Erica Yoon" # insert the co-pilot's name here e.g., "Michael Frank". If there are multiple co-pilots enter both names in a character string e.g., "Tom Hardwicke, Bob Dylan"
pilotTTC <- 500 # insert the pilot's estimated time to complete (in minutes, fine to approximate) e.g., 120
copilotTTC <- 120 # insert the co- pilot's estimated time to complete (in minutes, fine to approximate) e.g., 120
pilotStartDate <- as.Date("11/5/2017", format = "%m/%d/%y") # insert the pilot's start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
copilotStartDate <- as.Date("10/19/2018", format = "%m/%d/%y") # insert the co-pilot's start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
completionDate <- as.Date("", format = "%m/%d/%y") # copilot insert the date of final report completion (after any necessary rounds of author assistance) in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
```

-------

#### Methods summary: 

The authors conducted a repeated measures ANOVA using DFT as a repeated measure and judgement type as between-subjects factor. They report a significant main effect of DFT and a signficant interaction effect of DFT with judgment type. The plot mean judgement for attractiveness and mean judgement for trustworthiness across the ten faces in figure 2.

------

#### Target outcomes: 
> We complemented our by-face analysis with a by-participant
repeated measures analysis of variance
(ANOVA) with DFT as a repeated measure and judgment
type (trustworthiness vs. attractiveness) as a between-subjects
factor. The observed effects supported the same
conclusions as the by-face analysis. The main effect of
DFT was significant, F(10, 37) = 4.05, p < .001, ηp2 = .52.
More important, this main effect was qualified by a significant
interaction, F(10, 37) = 5.95, p < .001, ηp2 = .62.

------

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
```

## Step 1: Load packages

```{r}
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(CARPSreports) # custom report functions
library(ggplot2)
library(psych)
library(plyr)
library(corrplot)
library(car)
library(ez) #For ANOVA Models
```

```{r}
# Prepare report object. This will be updated automatically by the reproCheck function each time values are compared.
reportObject <- data.frame(dummyRow = TRUE, reportedValue = NA, obtainedValue = NA, valueType = NA, percentageError = NA, comparisonOutcome = NA, eyeballCheck = NA)
```

## Step 2: Load data

```{r}
faces <- read.csv("data/Experiment _1_Rps _v2.csv")
```

## Step 3: Tidy data

```{r}
faces$id <- c(1:48) #adding a new column for subject ID

tidyfaces <- faces %>%
  gather(key="DFT_Rating", value, 3:35) %>%
  separate(DFT_Rating, c("dft", "value_trial"), sep="T_") %>%
  subset(select = -dft) %>%
  separate(value_trial, c("dft_value", "trial_num"), sep="_") %>% 
  spread(trial_num, value)

```

## Step 4: Run analysis

### Pre-processing

```{r}
colnames(tidyfaces) <- c("age", "trust_attract", "id", "dft_value", "trial_1", "trial_2", "trial_3") #renaming the columns 

avg_value <-rowMeans(tidyfaces[,5:7]) #Calculating the avg value for each participant across the three tirals
tidyfaces$avg_value <- avg_value #adding this column into the dataframe

tidyfaces$dft_value <- as.numeric(tidyfaces$dft_value)
tidyfaces$trust_attract <- as.factor(tidyfaces$trust_attract)
```

### Descriptive statistics

```{r}
#Mean and SD for ratings across judement type (trustworthy / attractiveness):

tidyfaces %>%
  filter(trust_attract==1) %>%
  summarise(mean = mean(avg_value), 
            sd = sd(avg_value))

tidyfaces %>%
  filter(trust_attract==0) %>%
  summarise(mean = mean(avg_value), 
            sd = sd(avg_value))

attract_mean = c()
attract_sd = c()
trust_mean = c()
trust_sd = c()

for (i in 0:10){
  a = tidyfaces %>%
  filter(trust_attract==0 & dft_value == 10*i) %>%
  summarise(mean = mean(avg_value), 
            sd = sd(avg_value))
  attract_mean = c(attract_mean, a$mean)
  attract_sd = c(attract_sd, a$sd)

  
  t = tidyfaces %>%
  filter(trust_attract==1 & dft_value == 10*i) %>%
  summarise(mean = mean(avg_value), 
            sd = sd(avg_value))
  trust_mean = c(trust_mean, t$mean)
  trust_sd = c(trust_sd, t$sd)
}

df = data.frame("dft_value"=seq(0,100,10))
df = mutate(df, "trust_mean" = trust_mean
            , "trust_sd" = trust_sd
            , "attract_mean" = attract_mean
            , "attract_sd" = attract_sd)

print(df)

```

We are really interested in the mean(SD) judgement for attractiveness and trustworthiness for all participants for each value of DFT. It was simplier to find this using a for loop to calculate each of the 20 mean values and enter them into a dataframe.

### Inferential statistics

### Model 1:

```{r, model 1}

#Model 1 - Repeated Measures ANOVA 
tidyfaces$trust_attract = as.factor(tidyfaces$trust_attract)
tidyfaces$dft_value = as.factor(tidyfaces$dft_value)
tidyfaces$id = as.factor(tidyfaces$id)
model1 <- with(tidyfaces, aov(avg_value ~ dft_value * trust_attract + Error(id / dft_value)))
summary(model1)
```

Our goal was to reproduce the analysis of the authors in experiemnt one. we conducted a by-participant repeated measures analysis of variance using the value of DFT as a repeated measure and judgment type (either trustworthiness or attractiveness) as a between-subjects factor.

The main effect of DFT was significant, F(10, 46) = 10.50, p < .001. There was also a significant interaction between DFT and Judgement Type  interaction, F(10, 460) = 43.75, p < .001.

ηp2 could not be caluculated with this model, but we will check this output and calculate ηp2 below. 


### Model 2: 

```{r, mod 2}
#Model 2 - Repeated Measures ANOVA
tidyfaces$trust_attract <- as.factor(tidyfaces$trust_attract)
tidyfaces$dft_value <- as.factor(tidyfaces$dft_value)
tidyfaces$id <- as.factor(tidyfaces$id)
model2 <- ezANOVA(data = tidyfaces, dv = .(avg_value), wid = .(id), within = .(dft_value), between = .(trust_attract), detailed = TRUE, return_aov=T)

model2$ANOVA
print(model2)
```

Because we found differnt outcomes above and we could not obtain all the values reported by the authors, here we try a slightly differnt model using a different R package.

The main effect of DFT was significant, F(10, 46) = 10.49, p < .001, ηp2 = 0.082. There was also a significant interaction between DFT and Judgement Type  interaction, F(10, 460) = 43.75, p < .001, ηp2 = 0.27.

### Figure 2 Replication:

```{r, Fig 2 Rep}
#Figure 2 Replication
pd <- position_dodge(0.1)
ggplot() + 
  geom_line(data = df, aes(x = dft_value, y = attract_mean), color = "green") + 
    geom_errorbar(aes(x = df$dft_value, ymin = attract_mean - attract_sd/sqrt(528), ymax = attract_mean + attract_sd/sqrt(528)), width=.1, position = pd)  + geom_line(data = df, aes(x = dft_value, y = trust_mean), color = "blue") +
  geom_errorbar(aes(x = df$dft_value, ymin = trust_mean - trust_sd/sqrt(528), ymax = trust_mean + trust_sd/sqrt(528)), width=.1,
position = pd)  +  xlab('DFT Value') + ylab('Mean Judgment') + ylim(0, 10) + scale_x_continuous(breaks=seq(0,100,10))

```

Figure 2: Mean trustworthiness and attractiveness judgments as a function of DFT. Error bars represent within-subjects standard errors.


### Errors:

```{r}

#ANOVA Output - Main Effect of DFT
reportObject <- reproCheck(reportedValue = "4.05", obtainedValue = 10.50, valueType = 'F')

#ANOVA Output - Interaction Effect of DFT with Judgment Type
reportObject <- reproCheck(reportedValue = "5.95", obtainedValue = 43.75, valueType = 'F')

#ANOVA Output - F Test Degrees of Freedom 
reportObject <- reproCheck(reportedValue = "37", obtainedValue = 46, valueType = 'df')

```

## Step 5: Conclusion

In conclusion, we attempted to replicate a main finding from the Sofer et al., paper. The authors conducted a by-participant repeated measures analysis of variance (ANOVA) with DFT as a repeated measure and judgment type (trustworthiness vs. attractiveness) as a between-subjects factor. They report a significant main effect of DFT ( F(10, 37) = 4.05, p < .001, ηp2 = .52). The authors also found a significant interaction, F(10, 37) = 5.95, p < 0.001, ηp2 = 0.62

Our attempt to calculate these same findings failed. We believe this could be due to confusion over the number of subjects included. As reported above, it looks as though the authors only inlcuded 38 of the 48 subjects, indicated by a DF=37, or this was a typo in the manuscript. If certain participants were excluded from the analysis, it was not indicated other than the above DF error.

We found nearly identical values in two different ANOVA models, both of which differed from the authors reported findings.

We were generally able to replicate the figure depicting mean trustworthiness and attractiveness judgments as a function of distance of the face from the typical face (DFT).


```{r}
Author_Assistance = FALSE # was author assistance provided? (if so, enter TRUE)

Insufficient_Information_Errors <- 0 # how many discrete insufficient information issues did you encounter?

# Assess the causal locus (discrete reproducibility issues) of any reproducibility errors. Note that there doesn't necessarily have to be a one-to-one correspondance between discrete reproducibility issues and reproducibility errors. For example, it could be that the original article neglects to mention that a Greenhouse-Geisser correct was applied to ANOVA outcomes. This might result in multiple reproducibility errors, but there is a single causal locus (discrete reproducibility issue).

locus_typo <- NA # how many discrete issues did you encounter that related to typographical errors?
locus_specification <- NA # how many discrete issues did you encounter that related to incomplete, incorrect, or unclear specification of the original analyses?
locus_analysis <- NA # how many discrete issues did you encounter that related to errors in the authors' original analyses?
locus_data <- NA # how many discrete issues did you encounter that related to errors in the data files shared by the authors?
locus_unidentified <- NA # how many discrete issues were there for which you could not identify the cause

Affects_Conclusion <- NA # Do any reproducibility issues encounter appear to affect the conclusions made in the original article? This is a subjective judgement, but you should taking into account multiple factors, such as the presence/absence of decision errors, the number of target outcomes that could not be reproduced, the type of outcomes that could or could not be reproduced, the difference in magnitude of effect sizes, and the predictions of the specific hypothesis under scrutiny.
```

```{r}
reportObject <- reportObject %>%
  filter(dummyRow == FALSE) %>% # remove the dummy row
  select(-dummyRow) %>% # remove dummy row designation
  mutate(articleID = articleID) %>% # add the articleID 
  select(articleID, everything()) # make articleID first column

# decide on final outcome
if(any(reportObject$comparisonOutcome != "MATCH") | Insufficient_Information_Errors > 0){
  finalOutcome <- "Failure without author assistance"
  if(Author_Assistance == T){
    finalOutcome <- "Failure despite author assistance"
  }
}else{
  finalOutcome <- "Success without author assistance"
  if(Author_Assistance == T){
    finalOutcome <- "Success with author assistance"
  }
}

# collate report extra details
reportExtras <- data.frame(articleID, pilotNames, copilotNames, pilotTTC, copilotTTC, pilotStartDate, copilotStartDate, completionDate, Author_Assistance, finalOutcome, Insufficient_Information_Errors, locus_typo, locus_specification, locus_analysis, locus_data, locus_unidentified)

# save report objects
if(reportType == "pilot"){
  write_csv(reportObject, "pilotReportDetailed.csv")
  write_csv(reportExtras, "pilotReportExtras.csv")
}

if(reportType == "final"){
  write_csv(reportObject, "finalReportDetailed.csv")
  write_csv(reportExtras, "finalReportExtras.csv")
}
```

# Session information

```{r session_info, include=TRUE, echo=TRUE, results='markup'}
devtools::session_info()
```

